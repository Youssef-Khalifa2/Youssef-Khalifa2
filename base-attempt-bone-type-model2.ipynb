{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c3ca05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:26:54.146686Z",
     "iopub.status.busy": "2024-06-09T09:26:54.146001Z",
     "iopub.status.idle": "2024-06-09T09:27:07.309820Z",
     "shell.execute_reply": "2024-06-09T09:27:07.308812Z"
    },
    "papermill": {
     "duration": 13.173035,
     "end_time": "2024-06-09T09:27:07.312304",
     "exception": false,
     "start_time": "2024-06-09T09:26:54.139269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-09 09:26:56.026121: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-09 09:26:56.026240: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-09 09:26:56.152046: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "/tmp/ipykernel_24/3400929819.py:19: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import shutil\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Average, Dense ,Layer\n",
    "from tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, BatchNormalization,MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Concatenate, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler, TensorBoard\n",
    "from keras.layers import Concatenate\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.applications import Xception,EfficientNetB0\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import mixed_precision , applications,layers\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c281f3c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.324054Z",
     "iopub.status.busy": "2024-06-09T09:27:07.323511Z",
     "iopub.status.idle": "2024-06-09T09:27:07.328000Z",
     "shell.execute_reply": "2024-06-09T09:27:07.327116Z"
    },
    "papermill": {
     "duration": 0.012392,
     "end_time": "2024-06-09T09:27:07.329878",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.317486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_shape = (224, 224, 3)\n",
    "num_classes = 5  \n",
    "num_views = 7\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "092529c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.340595Z",
     "iopub.status.busy": "2024-06-09T09:27:07.340323Z",
     "iopub.status.idle": "2024-06-09T09:27:07.346846Z",
     "shell.execute_reply": "2024-06-09T09:27:07.346040Z"
    },
    "papermill": {
     "duration": 0.014168,
     "end_time": "2024-06-09T09:27:07.348811",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.334643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Source path of the model\\nsource_path = \"/kaggle/input/bone-type-midway-multi/keras/xception-trails/1/xceptionattentionregularizedno-hypertuning.keras\"\\n\\n# Destination path where you can write\\ndestination_path = \"/kaggle/working/model.keras\"\\n\\n# Copy the model file\\nshutil.copyfile(source_path, destination_path)\\n\\n# Now load the model from the copied file\\nmodel = load_model(destination_path)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Source path of the model\n",
    "source_path = \"/kaggle/input/bone-type-midway-multi/keras/xception-trails/1/xceptionattentionregularizedno-hypertuning.keras\"\n",
    "\n",
    "# Destination path where you can write\n",
    "destination_path = \"/kaggle/working/model.keras\"\n",
    "\n",
    "# Copy the model file\n",
    "shutil.copyfile(source_path, destination_path)\n",
    "\n",
    "# Now load the model from the copied file\n",
    "model = load_model(destination_path)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1d20a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.360029Z",
     "iopub.status.busy": "2024-06-09T09:27:07.359765Z",
     "iopub.status.idle": "2024-06-09T09:27:07.375850Z",
     "shell.execute_reply": "2024-06-09T09:27:07.374998Z"
    },
    "papermill": {
     "duration": 0.024006,
     "end_time": "2024-06-09T09:27:07.377757",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.353751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, labels, batch_size, image_shape, num_classes, num_views=num_views):\n",
    "        super().__init__()\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.labels = list(labels)\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_views = num_views\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_image_paths = [self.image_paths[i] for i in indices]\n",
    "        batch_labels = [self.labels[i] for i in indices]\n",
    "\n",
    "        images = []\n",
    "        for folder_path in batch_image_paths:\n",
    "            images.append(self._load_and_pad_images(folder_path, self.image_shape))\n",
    "\n",
    "        images = np.array(images)  # Shape: (batch_size, num_views, height, width, channels)\n",
    "        batch_labels = tf.keras.utils.to_categorical(batch_labels, num_classes=self.num_classes)\n",
    "\n",
    "        # Transpose the batch to separate views as different inputs\n",
    "        images = [images[:, i, :, :, :] for i in range(self.num_views)]\n",
    "        \n",
    "        # Convert to tuple of tensors\n",
    "        images = tuple(tf.convert_to_tensor(img) for img in images)\n",
    "        batch_labels = tf.convert_to_tensor(batch_labels)\n",
    "\n",
    "        return images, batch_labels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.image_paths))\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    def _load_and_pad_images(self, folder_path, image_shape):\n",
    "        image_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "                       if f.endswith((\".jpg\", \".jpeg\", \".png\")) and not f.startswith(\"._\")]\n",
    "\n",
    "        if not image_paths:\n",
    "            logger.error(f\"No valid images found in folder: {folder_path}\")\n",
    "            return [np.zeros((image_shape[0], image_shape[1], image_shape[2]))] * self.num_views\n",
    "\n",
    "        if len(image_paths) > self.num_views:\n",
    "            image_paths = random.sample(image_paths, self.num_views)\n",
    "\n",
    "        processed_images = []\n",
    "        for image_path in image_paths:\n",
    "            try:\n",
    "                img = load_img(image_path, target_size=image_shape)\n",
    "                img_array = img_to_array(img)\n",
    "                img_array = img_array / 255.0\n",
    "                preprocessed_img_array = preprocess_input(img_array)\n",
    "                processed_images.append(preprocessed_img_array)\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Warning: Skipping unidentifiable image file: {image_path} due to {e}\")\n",
    "                processed_images.append(np.zeros((image_shape[0], image_shape[1], image_shape[2])))\n",
    "\n",
    "        while len(processed_images) < self.num_views:\n",
    "            processed_images.append(np.zeros((image_shape[0], image_shape[1], image_shape[2])))\n",
    "\n",
    "        return np.array(processed_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd323492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.388982Z",
     "iopub.status.busy": "2024-06-09T09:27:07.388676Z",
     "iopub.status.idle": "2024-06-09T09:27:07.495010Z",
     "shell.execute_reply": "2024-06-09T09:27:07.494078Z"
    },
    "papermill": {
     "duration": 0.114543,
     "end_time": "2024-06-09T09:27:07.497399",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.382856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Path Bone_type\n",
      "9666   /kaggle/input/mura-v11/MURA-v1.1/train/XR_WRIS...         1\n",
      "9719   /kaggle/input/mura-v11/MURA-v1.1/train/XR_WRIS...         1\n",
      "5328   /kaggle/input/mura-v11/MURA-v1.1/train/XR_FING...         4\n",
      "2159   /kaggle/input/mura-v11/MURA-v1.1/train/XR_SHOU...         0\n",
      "4740   /kaggle/input/mura-v11/MURA-v1.1/train/XR_FING...         4\n",
      "...                                                  ...       ...\n",
      "8405   /kaggle/input/mura-v11/MURA-v1.1/train/XR_WRIS...         1\n",
      "12424  /kaggle/input/mura-v11/MURA-v1.1/train/XR_HAND...         2\n",
      "905    /kaggle/input/mura-v11/MURA-v1.1/train/XR_SHOU...         0\n",
      "5784   /kaggle/input/mura-v11/MURA-v1.1/train/XR_ELBO...         3\n",
      "235    /kaggle/input/mura-v11/MURA-v1.1/train/XR_SHOU...         0\n",
      "\n",
      "[9590 rows x 2 columns]\n",
      "===============Done with training images===================\n",
      "===============Done with test images===================\n"
     ]
    }
   ],
   "source": [
    "bone_type_mapping = {'SHOULDER': 0, 'WRIST': 1, 'HAND': 2, 'ELBOW': 3, 'FINGER': 4}\n",
    "prefix = '/kaggle/input/mura-v11/'\n",
    "output_directory = '/kaggle/working'\n",
    "train_excel_file_path = '/kaggle/input/csv-for-multiview/Patients with bone type for multiview.csv'\n",
    "df = pd.read_csv(train_excel_file_path, header=None,names=['Path', 'Abnormal','Bone_type'])\n",
    "df = df[~df['Path'].str.contains('XR_FOREARM|XR_HUMERUS')]\n",
    "df['Bone_type'] = df['Bone_type'].map(bone_type_mapping).astype(int)\n",
    "paths = prefix + df['Path'].astype(str)\n",
    "labels = df['Bone_type']\n",
    "labels = labels.astype(str)\n",
    "t_images = pd.concat([paths, labels], axis=1)\n",
    "train_df, test_df = train_test_split(t_images, train_size=0.8, shuffle=True, random_state=1)\n",
    "print(train_df)\n",
    "print(\"===============Done with training images===================\")\n",
    "test_excel_file_path = '/kaggle/input/csv-for-multiview/validation Patients with bone type for multiview.csv'\n",
    "df = pd.read_csv(test_excel_file_path, header=None,names=['Path', 'Abnormal','Bone_type'])\n",
    "df = df[~df['Path'].str.contains('XR_FOREARM|XR_HUMERUS')]\n",
    "df['Bone_type'] = df['Bone_type'].map(bone_type_mapping).astype(int)\n",
    "paths = prefix + df['Path'].astype(str)\n",
    "labels = df['Bone_type']\n",
    "labels = labels.astype(str)\n",
    "v_images = pd.concat([paths, labels], axis=1)\n",
    "print(\"===============Done with test images===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d11cbbd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.509497Z",
     "iopub.status.busy": "2024-06-09T09:27:07.508770Z",
     "iopub.status.idle": "2024-06-09T09:27:07.518599Z",
     "shell.execute_reply": "2024-06-09T09:27:07.517738Z"
    },
    "papermill": {
     "duration": 0.017815,
     "end_time": "2024-06-09T09:27:07.520489",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.502674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data Generators Initialization \n",
    "train_paths,train_labels = train_df['Path'] , train_df['Bone_type']\n",
    "valid_paths,valid_labels = test_df['Path'] , test_df['Bone_type']\n",
    "test_paths,test_labels = v_images['Path'] , v_images['Bone_type']\n",
    "\n",
    "train_generator = CustomDataGenerator(train_paths, train_labels, batch_size, image_shape, num_classes)\n",
    "valid_generator = CustomDataGenerator(valid_paths, valid_labels, batch_size, image_shape, num_classes)\n",
    "test_generator = CustomDataGenerator(test_paths, test_labels, batch_size, image_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f514ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.531988Z",
     "iopub.status.busy": "2024-06-09T09:27:07.531249Z",
     "iopub.status.idle": "2024-06-09T09:27:07.537224Z",
     "shell.execute_reply": "2024-06-09T09:27:07.536539Z"
    },
    "papermill": {
     "duration": 0.013644,
     "end_time": "2024-06-09T09:27:07.539134",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.525490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Callbacks Initialization\n",
    "checkpoint_path = '/kaggle/working/multiple_view_shoulder_v2.keras'\n",
    "Monitored_metric= 'val_loss' \n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = EarlyStopping(monitor=Monitored_metric,  # The metric to monitor for early stopping\n",
    "                               patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "                               verbose=1,  # Verbosity level\n",
    "                               restore_best_weights=True)  # Restore model weights from the epoch with the best value of the monitored metric\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_path,\n",
    "                                   monitor=Monitored_metric,  # The metric to monitor for saving the best model\n",
    "                                   save_best_only=True,  # Save only the best model\n",
    "                                   mode='min',  # Mode for the 'monitor' metric (e.g., 'min' for loss)\n",
    "                                   verbose=1)  # Verbosity level\n",
    "learn_control = tf.keras.callbacks.ReduceLROnPlateau(monitor=Monitored_metric, \n",
    "                                  patience=4,\n",
    "                                  verbose=1,\n",
    "                                  factor=0.2, \n",
    "                                  min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7c6528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.550041Z",
     "iopub.status.busy": "2024-06-09T09:27:07.549794Z",
     "iopub.status.idle": "2024-06-09T09:27:07.558428Z",
     "shell.execute_reply": "2024-06-09T09:27:07.557597Z"
    },
    "papermill": {
     "duration": 0.01619,
     "end_time": "2024-06-09T09:27:07.560247",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.544057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='AttentionLayer')\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.dense = None\n",
    "        self.attention_weights = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense = Dense(input_shape[-1], activation='tanh')\n",
    "        self.attention_weights = Dense(1)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        dense_features = self.dense(inputs)\n",
    "        raw_attention_scores = self.attention_weights(dense_features)\n",
    "        attention_scores = tf.nn.softmax(raw_attention_scores, axis=1)\n",
    "        context_vector = tf.reduce_sum(attention_scores * inputs, axis=1)\n",
    "        return context_vector\n",
    "        return context_vector\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='StackLayer')\n",
    "class StackLayer(Layer):\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super(StackLayer, self).__init__(**kwargs)\n",
    "        self.axis = axis\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.stack(inputs, axis=self.axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1ef3c",
   "metadata": {
    "papermill": {
     "duration": 0.004735,
     "end_time": "2024-06-09T09:27:07.569899",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.565164",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5fbf3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.580859Z",
     "iopub.status.busy": "2024-06-09T09:27:07.580573Z",
     "iopub.status.idle": "2024-06-09T09:27:07.591477Z",
     "shell.execute_reply": "2024-06-09T09:27:07.590627Z"
    },
    "papermill": {
     "duration": 0.018533,
     "end_time": "2024-06-09T09:27:07.593322",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.574789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "#Model Architecture\n",
    "def build_model(hp):\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=image_shape)\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = [Input(shape=image_shape) for _ in range(num_views)]\n",
    "\n",
    "    encoded_views = [base_model(view_input) for view_input in inputs]\n",
    "    pooled_views = [MaxPooling2D(pool_size=(2, 2))(view_output) for view_output in encoded_views]\n",
    "    # Apply GlobalAveragePooling to each view's output\n",
    "    pooled_views = [GlobalAveragePooling2D()(view_output) for view_output in pooled_views]\n",
    "\n",
    "    # Stack the pooled views to apply the attention mechanism\n",
    "    stacked_views = StackLayer(axis=1)(pooled_views)  # Shape: (batch_size, num_views, feature_dim)\n",
    "    \n",
    "    # Apply the attention layer\n",
    "    context_vector = AttentionLayer()(stacked_views)\n",
    "\n",
    "    # Add custom layers on top\n",
    "    #x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(context_vector)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #x = Dense(1024, activation='relu', kernel_regularizer=l2(0.001))(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    #x = Dropout(0.5)(x)\n",
    "    #predictions = Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "    x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(context_vector)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation=\"softmax\", kernel_regularizer=l2(0.001))(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=[\"accuracy\", \"recall\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89613e8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:07.604669Z",
     "iopub.status.busy": "2024-06-09T09:27:07.604047Z",
     "iopub.status.idle": "2024-06-09T09:27:12.552747Z",
     "shell.execute_reply": "2024-06-09T09:27:12.551932Z"
    },
    "papermill": {
     "duration": 4.957054,
     "end_time": "2024-06-09T09:27:12.555244",
     "exception": false,
     "start_time": "2024-06-09T09:27:07.598190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m83683744/83683744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='/kaggle/working/results',\n",
    "    project_name='xception_model_tuning'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a49f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T09:27:12.576000Z",
     "iopub.status.busy": "2024-06-09T09:27:12.575285Z",
     "iopub.status.idle": "2024-06-09T10:44:54.315519Z",
     "shell.execute_reply": "2024-06-09T10:44:54.314406Z"
    },
    "papermill": {
     "duration": 4661.997066,
     "end_time": "2024-06-09T10:44:54.561805",
     "exception": false,
     "start_time": "2024-06-09T09:27:12.564739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [01h 17m 42s]\n",
      "val_accuracy: 0.2918074429035187\n",
      "\n",
      "Best val_accuracy So Far: 0.2918074429035187\n",
      "Total elapsed time: 01h 17m 42s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_generator, validation_data=valid_generator, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dd96f7",
   "metadata": {
    "papermill": {
     "duration": 0.008883,
     "end_time": "2024-06-09T10:44:54.580406",
     "exception": false,
     "start_time": "2024-06-09T10:44:54.571523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=valid_generator,\n",
    "                    callbacks=[early_stopping,model_checkpoint, learn_control],\n",
    "                    epochs=80,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b183b865",
   "metadata": {
    "papermill": {
     "duration": 0.009152,
     "end_time": "2024-06-09T10:44:54.598554",
     "exception": false,
     "start_time": "2024-06-09T10:44:54.589402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df[['loss', 'val_loss']].plot()\n",
    "history_df[['accuracy','recall']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f102b8",
   "metadata": {
    "papermill": {
     "duration": 0.008925,
     "end_time": "2024-06-09T10:44:54.616665",
     "exception": false,
     "start_time": "2024-06-09T10:44:54.607740",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "loss, accuracy,recall = model.evaluate(test_generator)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 427555,
     "sourceId": 813639,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4776881,
     "sourceId": 8091050,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5064664,
     "sourceId": 8489424,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4686.519712,
   "end_time": "2024-06-09T10:44:57.965516",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-09T09:26:51.445804",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
